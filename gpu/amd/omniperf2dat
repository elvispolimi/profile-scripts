#!/usr/bin/env python3

import argparse
import csv
import os
import re
import sys
from collections import defaultdict


def parse_kernels(arg):
    return [k.strip() for k in arg.split(",") if k.strip()]


def kernel_label(name, kernels):
    for k in kernels:
        if k in name:
            return k
    return None


def normalize(s):
    return re.sub(r"[\s_\-]+", "", s.strip().lower())


def find_col(headers, candidates, override=None):
    if override:
        return override
    norm_headers = {normalize(h): h for h in headers}
    for c in candidates:
        key = normalize(c)
        if key in norm_headers:
            return norm_headers[key]
    return None


def parse_number(value):
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)
    s = str(value).strip()
    if not s:
        return None
    s = s.replace(",", "")
    m = re.search(r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?", s)
    if not m:
        return None
    num = float(m.group(0))
    unit = s[m.end() :].strip().lower()
    if unit.startswith("gb"):
        return num * 1_000_000_000.0
    if unit.startswith("mb"):
        return num * 1_000_000.0
    if unit.startswith("kb"):
        return num * 1_000.0
    if unit.startswith("ns"):
        return num * 1e-9
    if unit.startswith("us"):
        return num * 1e-6
    if unit.startswith("ms"):
        return num * 1e-3
    return num


def read_csv(path):
    with open(path, "r", newline="") as f:
        reader = csv.DictReader(f)
        rows = list(reader)
        return rows, reader.fieldnames or []


def parse_roofline_peaks(path):
    peaks = {}
    if not path or not os.path.exists(path):
        return peaks
    rows, headers = read_csv(path)
    if headers:
        col_map = {
            "hbm_peak": ["HBM BW", "HBM_BW", "HBM Bandwidth", "HBM Peak BW"],
            "l2_peak": ["L2 BW", "L2_BW", "L2 Bandwidth", "L2 Peak BW"],
            "l1_peak": ["L1 BW", "L1_BW", "L1 Bandwidth", "L1 Peak BW", "vL1 BW"],
            "peak_fp": ["Peak FP32", "Peak FLOPs FP32", "FP32 Peak", "Peak GFLOP/s FP32"],
            "peak_dp": ["Peak FP64", "Peak FLOPs FP64", "FP64 Peak", "Peak GFLOP/s FP64"],
        }
        for key, candidates in col_map.items():
            col = find_col(headers, candidates)
            if not col:
                continue
            values = []
            for row in rows:
                val = parse_number(row.get(col))
                if val is None:
                    continue
                values.append(val)
            if values:
                peaks[key] = sum(values) / len(values)
        if peaks:
            return peaks

    fallback_values = defaultdict(list)
    with open(path, "r") as f:
        for line in f:
            lower = line.lower()
            for key, patterns in {
                "hbm_peak": ["hbm bw", "hbm bandwidth"],
                "l2_peak": ["l2 bw", "l2 bandwidth"],
                "l1_peak": ["l1 bw", "l1 bandwidth", "vl1 bw"],
                "peak_fp": ["peak fp32", "peak flops fp32", "fp32 peak"],
                "peak_dp": ["peak fp64", "peak flops fp64", "fp64 peak"],
            }.items():
                if any(p in lower for p in patterns):
                    val = parse_number(line)
                    if val is not None:
                        fallback_values[key].append(val)
    for key, values in fallback_values.items():
        if values:
            peaks[key] = sum(values) / len(values)
    return peaks


def safe_div(numerator, denominator):
    if denominator in (None, 0):
        return 0.0
    return numerator / denominator


def merge_kernel_metrics_average(per_run_data):
    sums = defaultdict(lambda: defaultdict(float))
    counts = defaultdict(lambda: defaultdict(int))
    for run_data in per_run_data:
        for kernel, metrics in run_data.items():
            for key, value in metrics.items():
                sums[kernel][key] += value
                counts[kernel][key] += 1
    merged = {}
    for kernel, key_totals in sums.items():
        merged[kernel] = {
            key: key_totals[key] / counts[kernel][key]
            for key in key_totals
            if counts[kernel][key]
        }
    return merged


def average_peak_dicts(peaks_list):
    sums = defaultdict(float)
    counts = defaultdict(int)
    for peaks in peaks_list:
        for key, value in peaks.items():
            sums[key] += value
            counts[key] += 1
    return {key: sums[key] / counts[key] for key in sums if counts[key]}


def collect_kernel_metrics(rows, headers, kernels, args):
    kernel_col = find_col(
        headers,
        ["KernelName", "Kernel Name", "Kernel", "Name", "Kernel_Name"],
        args.kernel_col,
    )
    if not kernel_col:
        raise ValueError(f"Kernel name column not found. Headers: {headers}")

    fp32_perf_col = find_col(
        headers,
        ["FP32 GFLOP/s", "FP32_GFLOPS", "F32 GFLOP/s", "GFLOP/s (FP32)", "FP32 Gflops"],
        args.fp32_perf_col,
    )
    fp64_perf_col = find_col(
        headers,
        ["FP64 GFLOP/s", "FP64_GFLOPS", "F64 GFLOP/s", "GFLOP/s (FP64)", "FP64 Gflops"],
        args.fp64_perf_col,
    )

    fp32_flop_col = find_col(
        headers,
        ["FP32 FLOPs", "F32 FLOPs", "FLOPs FP32", "FLOPs (FP32)", "FLOPs"],
        args.fp32_flop_col,
    )
    fp64_flop_col = find_col(
        headers,
        ["FP64 FLOPs", "F64 FLOPs", "FLOPs FP64", "FLOPs (FP64)"],
        args.fp64_flop_col,
    )
    time_col = find_col(
        headers,
        ["DurationNs", "Duration (ns)", "Time (ns)", "Kernel Duration (ns)", "Time (us)", "Duration (us)"],
        args.time_col,
    )

    l1_ai_col = find_col(
        headers,
        ["L1 AI", "L1_AI", "AI L1", "L1 Arithmetic Intensity"],
        args.l1_ai_col,
    )
    l2_ai_col = find_col(
        headers,
        ["L2 AI", "L2_AI", "AI L2", "L2 Arithmetic Intensity"],
        args.l2_ai_col,
    )
    hbm_ai_col = find_col(
        headers,
        ["HBM AI", "HBM_AI", "AI HBM", "HBM Arithmetic Intensity"],
        args.hbm_ai_col,
    )

    l1_bytes_col = find_col(
        headers,
        ["L1 Bytes", "L1_BYTES", "L1 Bytes (B)", "L1 Bytes (bytes)", "L1_TEX_Bytes"],
        args.l1_bytes_col,
    )
    l2_bytes_col = find_col(
        headers,
        ["L2 Bytes", "L2_BYTES", "L2 Bytes (B)", "L2 Bytes (bytes)"],
        args.l2_bytes_col,
    )
    hbm_bytes_col = find_col(
        headers,
        ["HBM Bytes", "HBM_BYTES", "DRAM Bytes", "DRAM_BYTES", "HBM Bytes (B)", "DRAM Bytes (B)"],
        args.hbm_bytes_col,
    )
    lds_bytes_col = find_col(
        headers,
        ["LDS Bytes", "LDS_BYTES", "LDS Bytes (B)", "LDS Traffic (B)", "LDS Traffic"],
        args.lds_bytes_col,
    )

    occupancy_col = find_col(
        headers,
        [
            "Occupancy (%)",
            "Achieved Occupancy (%)",
            "Wavefront Occupancy (%)",
            "Wave Occupancy (%)",
            "Occupancy",
        ],
        args.occupancy_col,
    )
    occupancy_peak_col = find_col(
        headers,
        ["Peak Occupancy (%)", "Max Occupancy (%)", "Theoretical Occupancy (%)"],
        args.occupancy_peak_col,
    )
    efficiency_col = find_col(
        headers,
        [
            "Thread Efficiency (%)",
            "Wavefront Efficiency (%)",
            "SIMD Utilization (%)",
            "VALU Utilization (%)",
            "ALU Utilization (%)",
        ],
        args.efficiency_col,
    )

    insts_col = find_col(headers, ["SQ_INSTS", "Insts", "Instructions"], None)
    branch_col = find_col(headers, ["SQ_INSTS_BRANCH", "Insts Branch"], None)
    smem_col = find_col(headers, ["SQ_INSTS_SMEM"], None)
    lds_col = find_col(headers, ["SQ_INSTS_LDS"], None)
    vmem_rd_col = find_col(headers, ["SQ_INSTS_VMEM_RD"], None)
    vmem_wr_col = find_col(headers, ["SQ_INSTS_VMEM_WR"], None)
    valu_i32_col = find_col(headers, ["SQ_INSTS_VALU_INT32"], None)
    valu_i64_col = find_col(headers, ["SQ_INSTS_VALU_INT64"], None)
    valu_cvt_col = find_col(headers, ["SQ_INSTS_VALU_CVT"], None)
    valu_f16_add_col = find_col(headers, ["SQ_INSTS_VALU_ADD_F16"], None)
    valu_f16_mul_col = find_col(headers, ["SQ_INSTS_VALU_MUL_F16"], None)
    valu_f16_fma_col = find_col(headers, ["SQ_INSTS_VALU_FMA_F16"], None)
    valu_f32_add_col = find_col(headers, ["SQ_INSTS_VALU_ADD_F32"], None)
    valu_f32_mul_col = find_col(headers, ["SQ_INSTS_VALU_MUL_F32"], None)
    valu_f32_fma_col = find_col(headers, ["SQ_INSTS_VALU_FMA_F32"], None)
    valu_f64_add_col = find_col(headers, ["SQ_INSTS_VALU_ADD_F64"], None)
    valu_f64_mul_col = find_col(headers, ["SQ_INSTS_VALU_MUL_F64"], None)
    valu_f64_fma_col = find_col(headers, ["SQ_INSTS_VALU_FMA_F64"], None)
    mfma_col = find_col(headers, ["SQ_INSTS_MFMA"], None)
    mfma_f16_col = find_col(headers, ["SQ_INSTS_VALU_MFMA_F16"], None)
    mfma_bf16_col = find_col(headers, ["SQ_INSTS_VALU_MFMA_BF16"], None)
    mfma_f32_col = find_col(headers, ["SQ_INSTS_VALU_MFMA_F32"], None)
    mfma_f64_col = find_col(headers, ["SQ_INSTS_VALU_MFMA_F64"], None)
    mfma_i8_col = find_col(headers, ["SQ_INSTS_VALU_MFMA_I8"], None)

    sums = defaultdict(lambda: defaultdict(float))
    counts = defaultdict(lambda: defaultdict(int))

    def add(label, key, value):
        if value is None:
            return
        sums[label][key] += value
        counts[label][key] += 1

    for row in rows:
        kernel_name = row.get(kernel_col, "")
        label = kernel_label(kernel_name, kernels)
        if label is None:
            continue

        fp32_flop = parse_number(row.get(fp32_flop_col)) if fp32_flop_col else None
        fp64_flop = parse_number(row.get(fp64_flop_col)) if fp64_flop_col else None
        time_val = parse_number(row.get(time_col)) if time_col else None
        if time_val is not None and time_col and "us" in time_col.lower():
            time_val *= 1e-6
        if time_val is not None and time_col and "ns" in time_col.lower():
            time_val *= 1e-9

        if fp32_flop is not None and time_val not in (None, 0):
            add(label, "fp32_flop", fp32_flop)
            add(label, "time_s", time_val)
        elif fp32_perf_col:
            perf = parse_number(row.get(fp32_perf_col))
            add(label, "fp32_perf", perf)

        if fp64_flop is not None and time_val not in (None, 0):
            add(label, "fp64_flop", fp64_flop)
            add(label, "time_s", time_val)
        elif fp64_perf_col:
            perf = parse_number(row.get(fp64_perf_col))
            add(label, "fp64_perf", perf)

        if l1_bytes_col:
            val = parse_number(row.get(l1_bytes_col))
            add(label, "l1_bytes", val)
        if l2_bytes_col:
            val = parse_number(row.get(l2_bytes_col))
            add(label, "l2_bytes", val)
        if hbm_bytes_col:
            val = parse_number(row.get(hbm_bytes_col))
            add(label, "hbm_bytes", val)
        if lds_bytes_col:
            val = parse_number(row.get(lds_bytes_col))
            add(label, "lds_bytes", val)

        insts = parse_number(row.get(insts_col)) if insts_col else None
        add(label, "insts", insts)

        mem_inst = 0.0
        mem_seen = False
        for col in (smem_col, lds_col, vmem_rd_col, vmem_wr_col):
            val = parse_number(row.get(col)) if col else None
            if val is not None:
                mem_inst += val
                mem_seen = True
        if mem_seen:
            add(label, "mem_inst", mem_inst)

        cf_inst = parse_number(row.get(branch_col)) if branch_col else None
        add(label, "cf_inst", cf_inst)

        shared_inst = 0.0
        shared_seen = False
        for col in (smem_col, lds_col):
            val = parse_number(row.get(col)) if col else None
            if val is not None:
                shared_inst += val
                shared_seen = True
        if shared_seen:
            add(label, "shared_inst", shared_inst)

        int_inst = 0.0
        int_seen = False
        for col in (valu_i32_col, valu_i64_col):
            val = parse_number(row.get(col)) if col else None
            if val is not None:
                int_inst += val
                int_seen = True
        if int_seen:
            add(label, "int_inst", int_inst)

        fp_inst = 0.0
        fp_seen = False
        for col in (
            valu_f16_add_col,
            valu_f16_mul_col,
            valu_f16_fma_col,
            valu_f32_add_col,
            valu_f32_mul_col,
            valu_f32_fma_col,
            valu_f64_add_col,
            valu_f64_mul_col,
            valu_f64_fma_col,
            mfma_col,
            mfma_f16_col,
            mfma_bf16_col,
            mfma_f32_col,
            mfma_f64_col,
            mfma_i8_col,
        ):
            val = parse_number(row.get(col)) if col else None
            if val is not None:
                fp_inst += val
                fp_seen = True
        if fp_seen:
            add(label, "fp_inst", fp_inst)

        if valu_cvt_col:
            val = parse_number(row.get(valu_cvt_col))
            add(label, "misc_inst", val)

        if l1_ai_col:
            val = parse_number(row.get(l1_ai_col))
            add(label, "l1_ai", val)
        if l2_ai_col:
            val = parse_number(row.get(l2_ai_col))
            add(label, "l2_ai", val)
        if hbm_ai_col:
            val = parse_number(row.get(hbm_ai_col))
            add(label, "hbm_ai", val)

        if occupancy_col:
            val = parse_number(row.get(occupancy_col))
            add(label, "sustained_occupancy", val)
        if occupancy_peak_col:
            val = parse_number(row.get(occupancy_peak_col))
            add(label, "peak_occupancy", val)
        if efficiency_col:
            val = parse_number(row.get(efficiency_col))
            add(label, "efficiency", val)

    if not sums:
        raise ValueError("No kernels matched the provided list.")

    data = {}
    for kernel, key_totals in sums.items():
        data[kernel] = {
            key: key_totals[key] / counts[kernel][key]
            for key in key_totals
            if counts[kernel][key]
        }
    return data


def kernel_point_types(count):
    points = [5, 7, 9, 11, 13, 3, 4, 6, 8, 10, 12, 14]
    return [points[i % len(points)] for i in range(count)]


def escape_gnuplot_string(value):
    return value.replace("\\", "\\\\").replace('"', '\\"')


def main():
    parser = argparse.ArgumentParser(
        description="Generate gnuplot data file from rocprof-compute/omniperf CSV output."
    )
    parser.add_argument("--workload", required=True, help="Path to workload SOC directory")
    parser.add_argument("--kernels", required=True, help="Comma-separated list of kernel name substrings")
    parser.add_argument("--precision", default="fp32", choices=["fp32", "fp64"])
    parser.add_argument("--pmc", action="append", default=None, help="Override pmc_perf.csv path (repeatable)")
    parser.add_argument("--roofline", action="append", default=None, help="Override roofline.csv path (repeatable)")

    parser.add_argument("--kernel-col", default=None)
    parser.add_argument("--fp32-perf-col", default=None)
    parser.add_argument("--fp64-perf-col", default=None)
    parser.add_argument("--fp32-flop-col", default=None)
    parser.add_argument("--fp64-flop-col", default=None)
    parser.add_argument("--time-col", default=None)
    parser.add_argument("--l1-ai-col", default=None)
    parser.add_argument("--l2-ai-col", default=None)
    parser.add_argument("--hbm-ai-col", default=None)
    parser.add_argument("--l1-bytes-col", default=None)
    parser.add_argument("--l2-bytes-col", default=None)
    parser.add_argument("--hbm-bytes-col", default=None)
    parser.add_argument("--lds-bytes-col", default=None)
    parser.add_argument("--occupancy-col", default=None)
    parser.add_argument("--occupancy-peak-col", default=None)
    parser.add_argument("--efficiency-col", default=None)
    args = parser.parse_args()

    kernels = parse_kernels(args.kernels)
    if not kernels:
        raise ValueError("--kernels is required")

    workload = args.workload
    pmc_paths = args.pmc or [os.path.join(workload, "pmc_perf.csv")]
    roofline_paths = args.roofline or [os.path.join(workload, "roofline.csv")]

    run_data = []
    for pmc_path in pmc_paths:
        rows, headers = read_csv(pmc_path)
        run_data.append(collect_kernel_metrics(rows, headers, kernels, args))
    data = merge_kernel_metrics_average(run_data)

    peaks = average_peak_dicts([parse_roofline_peaks(path) for path in roofline_paths])

    kernel_order = [k for k in kernels if k in data]

    print(f"peak_fp = {peaks.get('peak_fp', 0)}")
    print(f"peak_dp = {peaks.get('peak_dp', 0)}")
    print(f"l1_peak = {peaks.get('l1_peak', 0)}")
    print(f"l2_peak = {peaks.get('l2_peak', 0)}")
    print(f"hbm_peak = {peaks.get('hbm_peak', 0)}")
    print(f"l1_peak_txn = {safe_div(peaks.get('l1_peak', 0), 32.0)}")
    print(f"l2_peak_txn = {safe_div(peaks.get('l2_peak', 0), 32.0)}")
    print(f"hbm_peak_txn = {safe_div(peaks.get('hbm_peak', 0), 32.0)}")
    print("inst_peak = 0")
    print(f"kernel_count = {len(kernel_order)}")

    point_types = kernel_point_types(len(kernel_order))
    roofline_sp_points = []
    roofline_dp_points = []
    roofline_inst_points = []
    roofline_shared_points = []
    instmix_lines = []
    occupancy_block = ["# kernel sustained_occupancy_pct peak_occupancy_margin_pct"]
    predication_block = ["# kernel efficiency"]

    for idx, kernel_name in enumerate(kernel_order):
        d = data[kernel_name]
        escaped_name = escape_gnuplot_string(kernel_name)
        print(f"kernel_name_{idx} = \"{escaped_name}\"")
        print(f"kernel_point_{idx} = {point_types[idx]}")

        sp_perf = 0.0
        if d.get("fp32_flop") and d.get("time_s"):
            sp_perf = d["fp32_flop"] / (d["time_s"] * 1_000_000_000.0)
        elif d.get("fp32_perf") is not None:
            sp_perf = d["fp32_perf"]

        dp_perf = 0.0
        if d.get("fp64_flop") and d.get("time_s"):
            dp_perf = d["fp64_flop"] / (d["time_s"] * 1_000_000_000.0)
        elif d.get("fp64_perf") is not None:
            dp_perf = d["fp64_perf"]

        l1_ai = 0.0
        l2_ai = 0.0
        hbm_ai = 0.0
        if d.get("fp32_flop") and d.get("l1_bytes"):
            l1_ai = safe_div(d["fp32_flop"], d["l1_bytes"])
        elif d.get("l1_ai") is not None:
            l1_ai = d["l1_ai"]
        if d.get("fp32_flop") and d.get("l2_bytes"):
            l2_ai = safe_div(d["fp32_flop"], d["l2_bytes"])
        elif d.get("l2_ai") is not None:
            l2_ai = d["l2_ai"]
        if d.get("fp32_flop") and d.get("hbm_bytes"):
            hbm_ai = safe_div(d["fp32_flop"], d["hbm_bytes"])
        elif d.get("hbm_ai") is not None:
            hbm_ai = d["hbm_ai"]

        if d.get("fp64_flop"):
            l1_dp_ai = safe_div(d["fp64_flop"], d.get("l1_bytes", 0.0))
            l2_dp_ai = safe_div(d["fp64_flop"], d.get("l2_bytes", 0.0))
            hbm_dp_ai = safe_div(d["fp64_flop"], d.get("hbm_bytes", 0.0))
        else:
            l1_dp_ai = l1_ai
            l2_dp_ai = l2_ai
            hbm_dp_ai = hbm_ai

        insts = d.get("insts", 0.0)
        time_s = d.get("time_s", 0.0)
        inst_perf = safe_div(insts, time_s * 1_000_000_000.0)

        l1_txn = safe_div(d.get("l1_bytes", 0.0), 32.0)
        l2_txn = safe_div(d.get("l2_bytes", 0.0), 32.0)
        hbm_txn = safe_div(d.get("hbm_bytes", 0.0), 32.0)
        l1_total_32b_txn = l1_txn
        l1_inst_intensity = safe_div(insts, l1_total_32b_txn)
        l2_inst_intensity = safe_div(insts, l2_txn)
        hbm_inst_intensity = safe_div(insts, hbm_txn)

        shared_inst = d.get("shared_inst", 0.0)
        shared_txn = safe_div(d.get("lds_bytes", 0.0), 32.0)
        shared_perf = safe_div(shared_inst, time_s * 1_000_000_000.0)
        shared_intensity = safe_div(shared_inst, shared_txn)

        sustained_occ = d.get("sustained_occupancy", 0.0)
        peak_occ = d.get("peak_occupancy", 0.0)
        if peak_occ <= 0.0:
            peak_occ = 100.0
        peak_occ_margin = max(0.0, peak_occ - sustained_occ)

        efficiency = d.get("efficiency", 0.0)

        print(f"k{idx}_sp_perf = {sp_perf}")
        print(f"k{idx}_dp_perf = {dp_perf}")
        print(f"k{idx}_inst_perf = {inst_perf}")
        print(f"k{idx}_warp_shared_instruction_performance = {shared_perf}")
        print(f"k{idx}_shared_warp_inst_intensity = {shared_intensity}")
        print(f"k{idx}_l1_sp_intensity = {l1_ai}")
        print(f"k{idx}_l2_sp_intensity = {l2_ai}")
        print(f"k{idx}_hbm_sp_intensity = {hbm_ai}")
        print(f"k{idx}_l1_dp_intensity = {l1_dp_ai}")
        print(f"k{idx}_l2_dp_intensity = {l2_dp_ai}")
        print(f"k{idx}_hbm_dp_intensity = {hbm_dp_ai}")
        print(f"k{idx}_l1_inst_intensity = {l1_inst_intensity}")
        print(f"k{idx}_l2_inst_intensity = {l2_inst_intensity}")
        print(f"k{idx}_hbm_inst_intensity = {hbm_inst_intensity}")

        roofline_sp_points.append(
            f"[0:0:1] '+' us (k{idx}_l1_sp_intensity):(k{idx}_sp_perf) "
            f"with points lc rgb l1_color pt kernel_point_{idx} ps point_size title kernel_name_{idx}"
        )
        roofline_sp_points.append(
            f"[0:0:1] '+' us (k{idx}_l2_sp_intensity):(k{idx}_sp_perf) "
            f"with points lc rgb l2_color pt kernel_point_{idx} ps point_size notitle"
        )
        roofline_sp_points.append(
            f"[0:0:1] '+' us (k{idx}_hbm_sp_intensity):(k{idx}_sp_perf) "
            f"with points lc rgb hbm_color pt kernel_point_{idx} ps point_size notitle"
        )
        roofline_dp_points.append(
            f"[0:0:1] '+' us (k{idx}_l1_dp_intensity):(k{idx}_dp_perf) "
            f"with points lc rgb l1_color pt kernel_point_{idx} ps point_size title kernel_name_{idx}"
        )
        roofline_dp_points.append(
            f"[0:0:1] '+' us (k{idx}_l2_dp_intensity):(k{idx}_dp_perf) "
            f"with points lc rgb l2_color pt kernel_point_{idx} ps point_size notitle"
        )
        roofline_dp_points.append(
            f"[0:0:1] '+' us (k{idx}_hbm_dp_intensity):(k{idx}_dp_perf) "
            f"with points lc rgb hbm_color pt kernel_point_{idx} ps point_size notitle"
        )
        roofline_inst_points.append(
            f"[0:0:1] '+' us (k{idx}_l1_inst_intensity):(k{idx}_inst_perf) "
            f"with points lc rgb l1_color pt kernel_point_{idx} ps point_size title kernel_name_{idx}"
        )
        roofline_inst_points.append(
            f"[0:0:1] '+' us (k{idx}_l2_inst_intensity):(k{idx}_inst_perf) "
            f"with points lc rgb l2_color pt kernel_point_{idx} ps point_size notitle"
        )
        roofline_inst_points.append(
            f"[0:0:1] '+' us (k{idx}_hbm_inst_intensity):(k{idx}_inst_perf) "
            f"with points lc rgb hbm_color pt kernel_point_{idx} ps point_size notitle"
        )
        roofline_shared_points.append(
            f"[0:0:1] '+' us (k{idx}_shared_warp_inst_intensity):(k{idx}_warp_shared_instruction_performance) "
            f"with points lc rgb shared_color pt kernel_point_{idx} ps point_size title kernel_name_{idx}"
        )

        if insts > 0:
            fp_inst = d.get("fp_inst", 0.0)
            int_inst = d.get("int_inst", 0.0)
            mem_inst = d.get("mem_inst", 0.0)
            cf_inst = d.get("cf_inst", 0.0)
            misc_inst = d.get("misc_inst", 0.0)
            threadcomm_inst = 0.0
            known = fp_inst + int_inst + mem_inst + cf_inst + misc_inst + threadcomm_inst
            if known < insts:
                misc_inst += insts - known
            denom = insts
            instmix_lines.append(
                f"\"{escaped_name}\" "
                f"{(misc_inst / denom) * 100:.1f} {(threadcomm_inst / denom) * 100:.1f} "
                f"{(cf_inst / denom) * 100:.1f} {(mem_inst / denom) * 100:.1f} "
                f"{(int_inst / denom) * 100:.1f} {(fp_inst / denom) * 100:.1f}"
            )

        occupancy_block.append(f"\"{escaped_name}\" {sustained_occ} {peak_occ_margin}")
        predication_block.append(f"\"{escaped_name}\" {efficiency}")

    print("\nroofline_sp_points = \"" + ", ".join(roofline_sp_points) + "\"")
    print("\nroofline_dp_points = \"" + ", ".join(roofline_dp_points) + "\"")
    print("\nroofline_inst_points = \"" + ", ".join(roofline_inst_points) + "\"")
    print("\nroofline_shared_points = \"" + ", ".join(roofline_shared_points) + "\"")
    print("\n$occupancy << EOD")
    print("\n".join(occupancy_block))
    print("EOD")
    print("\n$predication << EOD")
    print("\n".join(predication_block))
    print("EOD")

    if instmix_lines:
        print("\n$instmix << EOD")
        print("\n".join(instmix_lines))
        print("EOD")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"error: {e}", file=sys.stderr)
        sys.exit(1)
